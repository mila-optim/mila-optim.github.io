---
title: "Mila Optimization Crash Course"
keywords: homepage
tags: [getting_started]
sidebar: mydoc_sidebar
---

# Mila Optimization Crash Course

## Description
This crash course is designed for practitioners who use optimization methods, such as SGD or ADAM, as black-box tools to train neural networks but want to gain a deeper understanding of the underlying principles of optimization. The course is structured into 10 lectures, each lasting 2 hours, with a specific focus for each semester on a different topic in optimization (e.g., first-order methods, second-order methods, stochastic optimization, etc.).

In every lecture, we will work through proofs step-by-step on the board, ensuring that the theoretical concepts are clear. To reinforce understanding, at least 30 minutes of each session will be dedicated to revisiting and redoing the proofs on your own. Lecture notes will be made available as we progress through the course. Everyone interested in learning more about optimization, regardless of their background, is welcome to join!

## When and Where
Wednesday 3-5pm, starting on September 04th, 2024. The course will be held in person at Mila, room A14 (building 6666).

## Organizers
- [Danilo Vucetic](https://scholar.google.com/citations?user=8ULqzpMAAAAJ&hl=en)
- [Lucas Maes](https://lucas-maes.github.io/)
- [Tianyue (Helen) Zhang](https://tianyuehz.github.io/)
- [Damien Scieur](https://damienscieur.github.io/)

### Alumni
- [Quentin Bertrand](https://qb3.github.io/)

{% include links.html %}
